---
title: "Computational Musicology- Final Portfolio"
author: "Alihan Ince"
date: ""
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    theme: "default"

---
Comparing French and Dutch Raps 
=========================================

Column 
-------------------------------------
### Exploring the Differences and Similarities Between Two Cultural Forms 

#### Introduction: The Corpus and the Purpose of the Study
[My corpus](https://open.spotify.com/playlist/7KtmJXjsDmw8WEdtyL28L3?si=0448a854bfd84eb5) consists of 300 tracks by the following French and Dutch rap artists and singers: Alonzo, Jul, PNL, Gims (French) and Lijpe, Boef, Sevn Alias, Josylvio (Dutch). So the corpus consists of both French and Dutch hip-hop music (raps).   
I deliberately chose this corpus because I often like listening to French and Dutch rappers myself.  
In terms of style and approach, French and Dutch rap are different, but both are characterized by their ability to engage with the issues and experiences of their respective communities, and both have made significant contributions to the development of hip-hop as a global cultural form. It is therefore worth researching rap music of both languages where we will look at the differences and similarities between the two.  
  
#### Differences and similairities between French and Dutch Rap
The natural groups are French rappers (Alonzo, Jul, PNL, Gims) and Dutch rappers (Lijpe, Boef, Sevn Alias, Josylvio).   
French rap is more characterized by its strong tradition of chanson (which is a style of song that emphasizes vocal performance and poetic lyrics) and French rappers often incorporate African and Carribean music into their work, while Dutch rappers incorporate elements of gabber and house into their work.  
Both groups produce rap which means that they both use a very fast and energetic flow as well as techniques such as Onomatopoeaia (sue of words that imitate sounds, such as "boom" or "snap").   
However, I am curious to see what the analyses will show. Each rapper obviously has his own way of rapping and, of course, does not always use the same technique. It is therefore important to generalise as much as possible when comparing raps in two languages. Moreover, I tried to keep the rappers as representative as possible.   
  
#### Selection of Rappers and Genres 
The chosen rappers produce raps in French and Dutch. So to make a comparison or look at differences between Dutch and French raps, I felt it was enough to choose two Dutch and two French artists.   
The corpus consist of raps and so it belongs to "Hip hop music" or "rap music". I think the tracks will cover the genre well since they are all raps. 
The only gap maybe is that tracks by rapper Alonzo are gangsta rap in addition to hip-hop. Furthermore, Jul also makes hip-house music and tracks by Boef and Lijpe belong to nederhop and street rap. ultimately, they do fall under the umbrella genre "Hip hop".  
  
#### Sample Tracks
Some typical typical sample tracks in my corpus are Ciao La France (Alonzo), Namek (Jul) and Hoofdpijn (Lijpe)   

Column 
-------------------------------------
### The Corpus 
```{=html}
<iframe src="https://open.spotify.com/embed/playlist/7KtmJXjsDmw8WEdtyL28L3?utm_source=generator&theme=0" width="100%" height="100%" frameBorder="0" allowtransparency="true" allow="encrypted-media" data-external="1"></iframe>
```

```{r}
library(tidyverse)
library(spotifyr)
library(plotly)
library(compmus)
library(tidymodels)
library(ggdendro)
library(heatmaply)

df <- get_playlist_audio_features("", "7KtmJXjsDmw8WEdtyL28L3?si=bc8137fcca564e11")

conditions <- c("QUARTIERS NORD", "Les dernières volontés de Mozart (Symphony)", "Cœur blanc", "Deux frères", 
                "L'EMPIRE DE MÉROÉ", "Dans la légende", "Capo Dei Capi Vol. II & III")
df$language <- ifelse(df$track.album.name %in% conditions, "French", "Dutch")

df_dutch <- df[df$language == "Dutch", ]
df_french <- df[df$language == "French", ]
 
cm23 <-
  bind_rows( 
    df_french |> mutate(category = "French"),
    df_dutch |> mutate(category = "Dutch")
  )
```

<!-- # Dutch Tracks -->
<!-- ```{r} -->
<!-- valueBox(nrow(df_dutch), icon="fa-music") -->
<!-- ``` -->

<!-- # French Tracks -->
<!-- ```{r} -->
<!-- valueBox(nrow(df_french), icon="fa-music") -->
<!-- ``` -->


Feature analysis {.storyboard} 
=========================================
### The Energetic Beat: Exploring the Relationship between Tempo and Danceability in Hip Hop Music 
```{r, fig.width=8, fig.height=7}
p1 <- cm23 %>%
  mutate(
    mode = ifelse(mode == 0, "Minor", "Major"),
    name = track.name
  ) %>%
  ggplot(
    aes(
      x = tempo, 
      y = danceability,
      size = energy,
      colour = mode,
      name = name
    )
  ) +
  geom_point() +
  geom_rug(linewidth = 0.2) +
  facet_wrap(~ category) +
  scale_x_continuous(
    limits = c(50, 200),
    breaks = c(50, 125, 200),
    minor_breaks = NULL
  ) +
  scale_y_continuous(
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),
    minor_breaks = NULL
  ) +
  scale_colour_brewer(
    type = "qual",
    palette = "Dark2"
  ) +
  scale_size_continuous(
    trans = "exp",
    #guide = "none",
    range = c(0, 2)
  ) + 
  theme_bw() +
  labs(
    x = "Tempo",
    y = "Danceability",
    colour = "Mode"
  ) + ggtitle("Relationship between tempo, danceability, energy in French & Dutch Hip hop")

ggplotly(p1)
```

***

In general, hip hop music is known for having a strong beat and a high level of energy. This is reflected in the tempo and danceability of many hip hop tracks, which are often fast and rhythmically complex.   
This plot really shows this relationship. A large proportion of tracks correspond to high energy and the "danceability" is well over 0.5 on average. Furthermore, we see interesting differences such as that the average tempo of Dutch raps is lower than French raps. The tempo distribution of French raps is greater than that of Dutch raps. This may be the reason why French raps more often give me more energy than Dutch raps.  

### Rhythmic Resonance bewteen Valence, Energy, and Loudness in French and Dutch Raps
```{r, fig.width=8, fig.height=7}
ggplot(cm23, mapping = aes(x = valence, y = energy, size=loudness)) +
  geom_boxplot(alpha = 0.5) + 
  geom_jitter(alpha = 0.5, color = "black") + 
  facet_wrap(~ category) +
  scale_size_continuous(
    trans = "exp",
    guide = "none",
    range = c(1, 5)) +
  ggtitle("Relationship between valence, energy and loudness in French & Dutch Hip hop") +
  theme_bw() 
```

***

This plot shows the relationship between the features "valence", "energy" and "Loudness" in French and Dutch raps. In the figure, the higher the valence and tempo be, the higher the loudness of the tracks be. Furthermore, the average energy of Dutch raps is lower, but whether this is significantly lower is questionable, as a discussion point is that the corpus contains slightly less Dutch rap than French rap. Lastly, the distribution of valence is almost the same in both cases


### Histograms of key modes for French and Dutch tracks in the corpus (WEEK 10)
```{r, fig.width=8, fig.height=7}
histcm23mode <- cm23 |>
     ggplot(aes(x = key_mode)) +
     geom_histogram(stat="count") +
     facet_wrap(~category) +
     ggtitle("The key mode the track is in for French & Dutch Hip hop") +
     theme_bw() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

ggplotly(histcm23mode)
```

***
This graph shows the number of times a major/minor key appeared in the entire corpus. It shows that almost every key appears in the corpus, but looking at the Dutch corpus, the D# major does not appear and F major appeared only once. This result corresponds to the French corpus in which D# major appeared only once and F# major did not appear at all. Moreover, A# major did not occur at all in the French corpus while it occurred five times in the Dutch corpus. Among other things, this would perhaps explain the difference between the two corpora. In the end, no difference is directly visible in the number of times a particular key did or did not occur in the corpus. 

### SD Tempo vs. Mean Tempo (Track-Level).
```{r, fig.width=8, fig.height=7}
sliced_french <- df_french |> slice(1:50) |> add_audio_analysis()
sliced_dutch <- df_dutch |> slice(1:50) |> add_audio_analysis()

sliced_df <-
  sliced_french |>
  mutate(genre = "French") |>
  bind_rows(sliced_dutch |> mutate(genre = "Dutch"))

# Plot
sliced_df |>
  mutate(
    sections =
      map(
        sections,                                    # sections or segments
        summarise_at,
        vars(tempo, loudness, duration),             # features of interest
        list(section_mean = mean, section_sd = sd)   # aggregation functions
      )
  ) |>
  unnest(sections) |>
  ggplot(
    aes(
      x = tempo,
      y = tempo_section_sd,
      colour = genre,
      alpha = loudness
    )
  ) +
  geom_point(aes(size = duration / 60)) +
  geom_rug() +
  theme_minimal() +
  ylim(0, 5) +
  labs(
    x = "Mean Tempo (bpm)",
    y = "SD Tempo",
    colour = "Genre",
    size = "Duration (min)",
    alpha = "Volume (dBFS)"
  ) +
  scale_size_continuous(
    trans = "exp",
    range = c(1, 4))
```

***
The standard deviation, denoted by σ, is a metric that quantifies the degree of dispersion of data with respect to the mean. When the standard deviation is low, the data points tend to be tightly clustered around the mean, while a high standard deviation implies that the data points are widely spread out [1]. 
In this graph, for each track, the Standard Deviation of "tempo" is plotted against the Average Tempo (bpm) in that same track. This has been done for both French and Dutch Raps. Thereby, the variable Volume (in dBFS) and Duration (in minutes) can be read from the graph. From the graph we can see that, as shown earlier, Dutch raps are clustered closer together when it comes to tempo. In this graph, you can see a similar result, namely, that Dutch rap has a lower average tempo than French Raps. I experience this difference in tempo myself when listening to Dutch and French raps. The average tempo of French raps are generally more spread out. The Standard Deviation in tempo for both genres (in this case languages) do not differ much from each other. We can see that when the average tempo is lower, the Standard Deviation is higher. Finally, we also see that tracks with a higher volume have a higher average tempo and a lower Standard Deviation and generally last more than three minutes. 

Reference: 
1. U.S. National Library of Medicine. (n.d.). Standard Deviation. https://www.nlm.nih.gov/nichsr/stats_tutorial/section2/mod8_sd.html

###  The most promising herald, poised to set these languages asunder, an unmistakable marker of distinction! (Track-Level).
```{r, fig.width=8, fig.height=7}
sliced_df |>
  mutate(
    timbre =
      map(
        segments,
        compmus_summarise,
        timbre,
        method = "mean"
      )
  ) |>
  select(genre, timbre) |>
  compmus_gather_timbre() |>
  ggplot(aes(x = basis, y = value, fill = genre)) +
  geom_violin() +
  scale_fill_viridis_d() +
  labs(x = "Spotify Timbre Coefficients", y = "", fill = "Genre")
```

***
In this graph, the average timbre coefficients in French and Dutch raps were analysed to come to a conclusion about which coefficient might make the most difference. Looking at the graph, we see that almost all coefficients are the same for both genres. To still point out a difference, we can say that coefficient 7 differs the most. So, coefficient 7 looks like the most promising marker distinguishing these genres, but we should verify that with cepstrograms and listening tests of specific pieces.

Chromagram  
=========================================
Column 
-------------------------------------
***
In the case of French rap music in the corpus, analyzing the chromagram can provide insights into the tonal characteristics of the music and how they differ from other genres or regions. For example, it might reveal that French rappers tend to use certain chords or tonal centers more frequently than rappers from other countries, or that they use different melodic patterns or scales.

Analyzing the chromagram of a track of French rap such as this one could also be useful for identifying commonalities and differences between individual artists or sub-genres within French rap. For instance, it could reveal that one artist tends to use a particular tonal center or scale more frequently than others, or that certain sub-genres of French rap have distinct melodic or harmonic characteristics.

Comparing the chromagrams of two French tracks (outliers), "INTRO" and "MAINTENANT" from the playlist reveals significant differences in their pitch distribution. In "INTRO", over time, the focus of the pitches is on different Chords such as C, D and G, whereas in "MAINTENANT", there is a strong concentration of pitches around chord B and G. This means that "INTRO" is more complex and it has more different chord progressions.

```{=html}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/6H8njIysTyNsjD5CyPtqwN?utm_source=generator" width="100%" height="60%" frameBorder="0" allowtransparency="true" allow="encrypted-media" data-external="1"></iframe>
```
```{=html}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/5y2WMZ9UAYsA7qxRENID6l?utm_source=generator" width="100%" height="60%" frameBorder="0" allowtransparency="true" allow="encrypted-media" data-external="1"></iframe>
```

Column 
-------------------------------------
### "Chromagram of a recording of GIMS; INTRO." (Lowest danceability with one of the highest tempo)
```{r, fig.width=15, fig.height=7}
 wood <-
   get_tidy_audio_analysis("6H8njIysTyNsjD5CyPtqwN") |>
   select(segments) |>
   unnest(segments) |>
   select(start, duration, pitches)

 wood |>
   mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
   compmus_gather_chroma() |> 
   ggplot(
     aes(
       x = start + duration / 2,
       width = duration,
       y = pitch_class,
       fill = value
     )
   ) +
   geom_tile() +
   labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
   theme_minimal() +
   scale_fill_viridis_c()
```

### "Chromagram of a recording of GIMS; MAINTENANT" (Highest energy with averaged valence)
```{r, fig.width=15, fig.height=7}
 wood <-
   get_tidy_audio_analysis("5y2WMZ9UAYsA7qxRENID6l") |>
   select(segments) |>
   unnest(segments) |>
   select(start, duration, pitches)

 wood |>
   mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
   compmus_gather_chroma() |> 
   ggplot(
     aes(
       x = start + duration / 2,
       width = duration,
       y = pitch_class,
       fill = value
     )
   ) +
   geom_tile() +
   labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
   theme_minimal() +
   scale_fill_viridis_c()
```


Cepstrogram 
=========================================
Column
-------------------------------------
A cepstrogram serves as a graphical representation of a sound signal's spectral envelope. It displays time on the horizontal axis and frequency on the vertical axis, and is obtained by analyzing the cepstrum, which results from the Fourier transform of a sound's power spectrum logarithm. With its ability to analyze harmonics and other frequency components, the cepstrogram is a valuable tool for identifying the pitch and timbral distribution characteristics of individual notes or chords in musical recordings.

Comparing the tracks which I like the most reveals difference in between their timbral distributions. One of the most liked French and Dutch rap is "Au DD" of PNL and "Treinstation" of Boef respectively. 
On the one hand, in "Au DD", there isn't significantly a strong concentration (magnitude) of timbral characteristics around a specific spectral range. So, there is no frequency range where the sound is dominated by a particular quality or color that the song has a more balanced and consistent sound overall, without any one aspect of the sound dominating or standing out too much. 
On the other hand, "Treinstation" has more variation in different frequency ranges , with a stronger concentration of timbral characteristics around a certain frequency range. This could create a more unique and interesting sound for this piece. 

```{=html}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/115Hll8WWkQLeiDyXpgr47?utm_source=generator" width="100%" height="60%" frameBorder="0" allowtransparency="true" allow="encrypted-media" data-external="1"></iframe>
```
```{=html}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/7yHf12Fxf8I1Q8Lhq6XqpZ?utm_source=generator" width="100%" height="60%" frameBorder="0" allowtransparency="true" allow="encrypted-media" data-external="1"></iframe>
```

Column
-------------------------------------
### "Cepstrogram of a recording of PNL; Au DD" (French track also in "liked Songs" playlist)
```{r, fig.width=15, fig.height=7}
bztfrench <-
  get_tidy_audio_analysis("115Hll8WWkQLeiDyXpgr47?si=b0fe1f7f1b304fc7") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

bztfrench |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()
```

### "Cepstrogram of a recording of Boef; Treinstation" (Dutch track also in "liked Songs" playlist)
```{r, fig.width=15, fig.height=7}
bztdutch <-
  get_tidy_audio_analysis("7yHf12Fxf8I1Q8Lhq6XqpZ?si=75225860823b4bfb") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

bztdutch |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()
```



Self-similarity Matrices 
=========================================
Column
-------------------------------------
A self-similarity matrix helps to visualize and analyze the structure of a musical recording. It is created by comparing different sections of a piece of music and measuring the degree of similarity between them.

Here, both the similarity matrices based on chroma and timbre were evaluated for Au DD" of PNL and "Treinstation" of Boef.
The timbre-based self-similarity matrix (which refers to the tone color or quality of the sound) for "Au DD" doesn't clearly show block which indicate repeated patterns in the sound, whereas the self-similarity matrix based on timbre for "Treinstation" does. However, if one look carefully at the timbre-based self-similarity matrix for "Au DD", one can see two small lines parallel to the main diagonal line in the figure which means that there are repetitions in the track. 

The chroma-based self-similarity matrix (which refers to the pitch content of the music) of a recording of Boef; Treinstation” shows clearly small parallel lines indicating repeated patterns in the sound, whereas The chroma-based self-similarity matrix for "Au DD" does not.  

```{=html}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/115Hll8WWkQLeiDyXpgr47?utm_source=generator" width="100%" height="60%" frameBorder="0" allowtransparency="true" allow="encrypted-media" data-external="1"></iframe>
```

```{=html}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/7yHf12Fxf8I1Q8Lhq6XqpZ?utm_source=generator" width="100%" height="60%" frameBorder="0" allowtransparency="true" allow="encrypted-media" data-external="1"></iframe>
```

Column
-------------------------------------
### "Self-similarity Matrix (Timbre) of a recording of PNL; Au DD" (French)
```{r, fig.width=7, fig.height=7}
bztfrench |>
  compmus_self_similarity(timbre, "cosine") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

```

### "Self-similarity Matrix (Timbre) of a recording of Boef; Treinstation" (Dutch)
```{r, fig.width=7, fig.height=7}
bztdutch |>
  compmus_self_similarity(timbre, "cosine") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

```

Column
-------------------------------------
### "Self-similarity Matrix (Chroma) of a recording of PNL; Au DD"
```{r, fig.width=7, fig.height=7}
bztfrench |>
  compmus_self_similarity(pitches, "cosine") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

```

### "Self-similarity Matrix (Chroma) of a recording of Boef; Treinstation" (Dutch)
```{r, fig.width=7, fig.height=7}
bztdutch |>
  compmus_self_similarity(pitches, "cosine") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

```

Keygram 
=========================================
Column
-------------------------------------
The recording of GIMS; Apres Vous Madame is in the key of Am en Em and this is also obvious from the keygram. Throughout the piece, road keys Am and Em are 1 than all other keys and this can also be deduced from the graph on the right. After about 120th seconds, the keygram scores less well on Am, but overall it is correct. 

Furthermore, the recording of Boef; Probleem is in the key of GM, F, Eb, Cm and Dm. From the Keygram, this can also be seen if we look at G: min and and C: min, for example. After the 100th seconds, things get a bit worse. The keyrgram is getting worse. 

```{=html}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/1kVQzCxcSVhqf4rLJyGk50?utm_source=generator" width="100%" height="60%" frameBorder="0" allowtransparency="true" allow="encrypted-media" data-external="1"></iframe>
```
```{=html}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/1L8sanepRgDJlQTsPQ4mU1?utm_source=generator" width="100%" height="60%" frameBorder="0" allowtransparency="true" allow="encrypted-media" data-external="1"></iframe>
```
Column
-------------------------------------
```{r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
```

### "Keygram of a recording of GIMS; Apres Vous Madame" (French track also in "liked Songs" playlist)
```{r, fig.width=15, fig.height=7}
Keygram <-
  get_tidy_audio_analysis("1kVQzCxcSVhqf4rLJyGk50?si=d11761254d384f40") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  )

Keygram |> 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

### "Keygram of a recording of Boef; Probleem" (Dutch track also in "liked Songs" playlist)
```{r, fig.width=15, fig.height=7}
Keygram <-
  get_tidy_audio_analysis("1L8sanepRgDJlQTsPQ4mU1?si=a798c820436e4bdf") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  )

Keygram |> 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

Tempograms {.storyboard} 
=========================================
### Tempo Tales: Exploring the Rhythmic Differences between French and Dutch Tracks
```{r, fig.width=8, fig.height=7}
histcm23mode <- cm23 |>
  ggplot(aes(x = tempo)) +
  geom_histogram(aes(y = after_stat(density)),
                 colour = 1, fill = "grey") +
  geom_density() +
  facet_wrap(~category) +
  ggtitle("Histogram of tempi for French- and Dutch HipHop Tracks ") +
  theme_bw() 

ggplotly(histcm23mode)
```

***

The histogram shows the overall estimated tempo of each track in both corpora (French and Dutch) in Beats Per Minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration [1]. If we look at the density plots, we can see that the tempo of Dutch tracks has been distributed differently from those of French tracks. As it happens, Dutch tracks mainly have a tempo between 90 and 105 BPM, whereas the tempo of French tracks has been more equally distributed between 90 and 150 BPM. These results could also be seen in the "The Energetic Beat" plot from week 7 in "Feature analysis", where the relationship between Tempo, Danceability has been explored. 

1. Web API Reference | Spotify for Developers. (n.d.). https://developer.spotify.com/documentation/web-api/reference/#/operations/get-audio-features


### Tempograms of a recording of PNL; Au DD” (French)
```{r, fig.width=8, fig.height=7}
# Tempogram of a recording of PNL; Au DD” (French)
audd <- get_tidy_audio_analysis("115Hll8WWkQLeiDyXpgr47?si=97a15a00b86749f7")
audd |>
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) |>
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
```

*** 
The following plot is a Tempogram for "Au DD". As it happens, the track has a relatively steady tempo with occasional variations. I think taht these variations (highlights) are visual noise which is a product of tempo octaves. From the 150th seconds onwards, you can see that the relatively stable pattern changes to a higher tempo (between 150th and 170th second) and suddenly to a lower tempo (around 175th second). This can be attributed to the fact that between 150th and 170th second there is more music dropping out paired with a higher instrumentalness and speechiness. In the 175th second, there is a short silence both in speechiness and music overall. Furthermore, at the end, it can be seen that there is more frequent tempo changes, which can be explained by the sluggish instrument playing (usually every track ends like this). In the tempogram of this track the highlights at the end, seen in it's self similarity matrices are visible. 

```{=html}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/115Hll8WWkQLeiDyXpgr47?utm_source=generator" width="100%" height="60%" frameBorder="0" allowtransparency="true" allow="encrypted-media" data-external="1"></iframe>
```

### Tempograms of a recording of Boef; Treinstation” (Dutch)
```{r, fig.width=8, fig.height=7}
# Tempogram of a recording of Boef; Treinstation” (Dutch)
treinstation <- get_tidy_audio_analysis("7yHf12Fxf8I1Q8Lhq6XqpZ?si=bc426059e480488a")
treinstation |>
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) |>
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
```

*** 
As compared to the previous track "Au DD", this track "Treinstation" exhibits more frequent tempo changes and has more highlights besides its relatively stable tempo curve. from the moment the 30 tyh second is reached, the tempo curve leaves its stability for a short time (around 30 seconds) due to the change in instruments. This also happens in the 80 th second where more instruments drop out. In the tempogram of this track, the change in tempo curve could also be seen in the self similarity matrices, especially at points where some pieces get repeated (parallel lines to the diagonal). 

```{=html}
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/7yHf12Fxf8I1Q8Lhq6XqpZ?utm_source=generator" width="100%" height="60%" frameBorder="0" allowtransparency="true" allow="encrypted-media" data-external="1"></iframe>
```

Dendrograms and  Feature Importance{.storyboard} 
=========================================
### Hierarchical clustering
```{r, fig.width=8, fig.height=7}
get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit |> 
    collect_predictions() |> 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit |> 
    conf_mat_resampled() |> 
    group_by(Prediction) |> mutate(precision = Freq / sum(Freq)) |> 
    group_by(Truth) |> mutate(recall = Freq / sum(Freq)) |> 
    ungroup() |> filter(Prediction == Truth) |> 
    select(class = Prediction, precision, recall)
}

df <- get_playlist_audio_features("", "7KtmJXjsDmw8WEdtyL28L3?si=bc8137fcca564e11")

conditions <- c("QUARTIERS NORD", "Les dernières volontés de Mozart (Symphony)", "Cœur blanc", "Deux frères", 
                "L'EMPIRE DE MÉROÉ", "Dans la légende", "Capo Dei Capi Vol. II & III")
df$language <- ifelse(df$track.album.name %in% conditions, "French", "Dutch")

#___________________________________________________________________________________________________________________
df_dutch <- df[df$language == "Dutch", ]
df_french <- df[df$language == "French", ]

cm23 <-
  bind_rows( 
    df_french |> mutate(category = "French"),
    df_dutch |> mutate(category = "Dutch")
  )
#___________________________________________________________________________________________________________________
compmus23 <- get_playlist_audio_features("", "4tf7czDftxYDbtsbedX7SL?si=499575679e564f75")
sample_dutch <- tail(compmus23, 15)
sample_french <- head(compmus23, 15)
#___________________________________________________________________________________________________________________
compmus23clus <-
  compmus23 |>
  add_audio_analysis() |>
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) |>
  mutate(pitches = map(pitches, compmus_normalise, "clr")) |>
  mutate_at(vars(pitches, timbre), map, bind_rows) |>
  unnest(cols = c(pitches, timbre))

#___________________________________________________________________________________________________________________
compmus23_juice <-
  recipe(
    track.name ~
      speechiness +
      instrumentalness +
      tempo + `C#|Db`+ c06 +  c08 + c09 + c12,
    data = compmus23clus
  ) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors()) |> 
  #step_range(all_predictors()) |> 
  prep(compmus23clus |> mutate(track.name = str_trunc(track.name, 20))) |>
  juice() |>
  column_to_rownames("track.name")
#___________________________________________________________________________________________________________________
compmus23_dist <- dist(compmus23_juice, method = "euclidean")
#___________________________________________________________________________________________________________________
compmus23_dist |> 
     hclust(method = "complete") |> 
     dendro_data() |>
     ggdendrogram()
```

***

There are three primary types of linkage: single, average, and complete. In this dendrogram, the type "complete" was chosen because it gave the best cluster result. Using complete clustering for a playlist of fifteen French and fifteen Dutch tracks, one can clearly see that there are two main clusters. The reason that there are not of all tracks (there are 337) is because it became computationally very heavy and the graphs would otherwise look very cluttered.  The left cluster clearly contains (10/12) x 100% = 83.3% Dutch raps and the right cluster consists of (13/18) x 100% = 72.2% French raps. Thus, the language and features of the raps are clearly visible in this clustering.  From this, it can be concluded that French and Dutch raps clearly differ from each other. However, it remains to be seen which features cause this difference. For this we will have to see which features are most important in creating clusters. This can be seen under "Feature Importance (Feature Set)". 


### Heatmap
```{r, fig.width=8, fig.height=7}
heatmaply(
  compmus23_juice,
  hclustfun = hclust,
  hclust_method = "complete",  # Change for single, average, or complete linkage.
  dist_method = "euclidean"
)
```

*** 
Looking closely at this heatmap, one can see that the bottom left part of the heatmap is clearly lighter in colour. In addition, the top right part is also clearly lighter (greener/yellower) coloured and the middle forms a dark coloured diagonal from top left to bottom right. What can be concluded from this is that most Dutch raps (bottom left) clearly differ from French raps (top right) when it comes to features c08, speechiness, c06, C#/Db. Indeed, these features are stronger in Dutch raps than French raps. Moreover, we see that French raps clearly differ from Dutch raps when it comes to c09, instrumentalness, c12, and tempo. Earlier, we also saw that tempo was clearly a features that was less widespread in Dutch raps and more widespread in French raps. In short, there is clearly a distinction in both the most important features and the language of raps.


### Feature Importance (Feature Set)
```{r, fig.width=8, fig.height=7}
#Classification!
compmus23class <-
  bind_rows(
    sample_french |> mutate(playlist = "french"),
    sample_dutch |> mutate(playlist = "dutch")
  ) |> 
  add_audio_analysis()
#___________________________________________________________________________________________________________________
compmus23class_features <-
  compmus23class |>  # For your portfolio, change this to the name of your corpus.
  mutate(
    playlist = factor(playlist),
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(
        segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean",
      )
  ) |>
  mutate(pitches = map(pitches, compmus_normalise, "clr")) |>
  mutate_at(vars(pitches, timbre), map, bind_rows) |>
  unnest(cols = c(pitches, timbre))

#___________________________________________________________________________________________________________________
compmus23class_recipe <-
  recipe(
    playlist ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = compmus23class_features           # Use the same name as the previous block.
  ) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors())      # Converts to z-scores.
# step_range(all_predictors())    # Sets range to [0, 1].
#___________________________________________________________________________________________________________________
compmus23class_cv <- compmus23class_features |> vfold_cv(5)
#___________________________________________________________________________________________________________________
forest_model <-
  rand_forest() |>
  set_mode("classification") |> 
  set_engine("ranger", importance = "impurity")
indie_forest <- 
  workflow() |> 
  add_recipe(compmus23class_recipe) |> 
  add_model(forest_model) |> 
  fit_resamples(
    compmus23class_cv, 
    control = control_resamples(save_pred = TRUE)
  )
#___________________________________________________________________________________________________________________
workflow() |> 
  add_recipe(compmus23class_recipe) |> 
  add_model(forest_model) |> 
  fit(compmus23class_features) |> 
  pluck("fit", "fit", "fit") |>
  ranger::importance() |> 
  enframe() |> 
  mutate(name = fct_reorder(name, value)) |> 
  ggplot(aes(name, value)) + 
  geom_col() + 
  coord_flip() +
  theme_minimal() +
  labs(x = NULL, y = "Importance")

```

*** 
This plot clearly shows which features are important and the information from it can clearly be used to get some idea about which features would possibly contribute most to, for example, clustering. However, the problem is that if the code is run over and over again each time, the top few features may vary more or less slightly. It can clearly be seen that features like speechiness, the 9th coefficient of the timbre vector, and instrumentalness are the most important features. There are a total of eight features whose value of "importance" is higher than 0.5. So I decided to use these features in the "Heatmap" section (left button). The most important two features: speechiness and the 9th coefficient of the timbre vector will be used in "Feature Importance (feature Set Plot)" (right button) to see how the tracks differ from each other and whether Dutch and French tracks clearly form a separate cluster on their own or not. 

### Feature Importance (Feature Set Plot)
```{r, fig.width=8, fig.height=7}
compmus23class_features |>
  ggplot(aes(x = speechiness, y = c09, colour = playlist, size = energy)) +
  geom_point(alpha = 0.8) +
  scale_color_viridis_d() +
  labs(
    x = "Speechiness",
    y = "Timbre Component 9",
    size = "Energy",
    colour = "Playlist"
  )
```

*** 
In these plots, the features "speechiness" are plotted against the 9th coefficient of the timbre vector. Additionally, the size of the bubbles represents the strength of the energy. Unfortunately, there are few data points used in this plot, which makes generalization and drawing conclusions less reliable and accurate. However, we can clearly see that French rap has lower speechiness and higher c09, while Dutch rap has a lower average c09 but a slightly higher speechiness. It is also evident that the tracks form clusters on their own.

Conclusion 
=========================================
In this portfolio, the differences and similarities between French and Dutch rap music were explored through a collection of 300 tracks by French and Dutch rap artists. The portfolio found that French rap is characterized by its strong tradition of chanson and the incorporation of African and Caribbean music, while Dutch rap incorporates elements of gabber and house. Both groups use a fast and energetic flow, but there are differences in tempo and energy levels. The portfolio also analyzed the chromagrams of individual tracks, revealing differences in pitch distribution and chord progressions. Overall, the portfolio provides insight into the unique characteristics of French and Dutch rap and how they contribute to the development of hip-hop as a global cultural form.


